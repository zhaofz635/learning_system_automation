name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: 'å­¦ç”ŸID (å¦‚ test001)'
        required: true
        type: string
      score:
        description: 'æµ‹è¯•æˆç»© (0-5åˆ†)'
        required: true
        type: string
      cognitive_load:
        description: 'è®¤çŸ¥è´Ÿè·è¯„åˆ† (1-5åˆ†ï¼Œé€—å·åˆ†éš”)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      NLTK_DATA: /tmp/nltk_data  # è®¾ç½®å…¨å±€ NLTK_DATA ç›®å½•

    steps:
      # 1. æ£€å‡ºä»£ç 
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. è®¾ç½® Python ç¯å¢ƒ
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. å®‰è£…ä¾èµ–å¹¶é…ç½® NLTK
      - name: Install dependencies and setup NLTK
        run: |
          python -m pip install --upgrade pip
          pip install nltk
      
          python -c "import nltk; print('âœ… nltk version:', nltk.__version__)"
      
          # åˆ›å»ºç›®å½•
          mkdir -p /tmp/nltk_data
      
          # ä¸‹è½½ punkt å’Œ punkt_tab
          python -c "
          import nltk
          nltk.download('punkt', download_dir='/tmp/nltk_data', quiet=True)
          nltk.download('punkt_tab', download_dir='/tmp/nltk_data', quiet=True)
          " || { echo 'âŒ Failed to download nltk resources'; exit 1; }
      
          # éªŒè¯ç›®å½•å†…å®¹
          echo 'ğŸ” Checking /tmp/nltk_data/tokenizers:'
          find /tmp/nltk_data -type f -name "*.pickle" -o -name "*.zip" | grep -i punkt | head -10
      
          # æµ‹è¯•åˆ†è¯ï¼ˆç¡®ä¿è·¯å¾„å·²æ·»åŠ ï¼‰
          python -c "
          import nltk
          nltk.data.path.append('/tmp/nltk_data')
          tokens = nltk.word_tokenize('Hello world. How are you?')
          print(f'âœ… Tokenization successful: {tokens}')
          " || { echo 'âŒ nltk setup failed'; exit 1; }
      
          # è®¾ç½®ç¯å¢ƒå˜é‡
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV
            # 4. å‡†å¤‡è¾“å…¥æ•°æ®
            - name: Prepare input files
              run: |
                echo '{
                  "student_id": "${{ inputs.student_id }}",
                  "score": ${{ inputs.score }},
                  "cognitive_load": [${{ inputs.cognitive_load }}]
                }' > input_data.json
      
                echo "ğŸ“„ Generated input_data.json:"
                cat input_data.json

      # 5. è¿è¡Œåˆ†æè„šæœ¬
      - name: Run analysis script
        env:
          Access_Key_Secret: ${{ secrets.Access_Key_Secret }}
          NLTK_DATA: /tmp/nltk_data
          PYTHONPATH: ${{ env.PYTHONPATH }}
        run: |
          which python
          python -c "
          import nltk
          nltk.data.path.append('/tmp/nltk_data')
          print('âœ… Running nltk version:', nltk.__version__)
          print('NLTK data paths:', nltk.data.path)
          " || { echo "âŒ nltk not available at runtime"; exit 1; }

          # æ‰§è¡Œä¸»åˆ†æè„šæœ¬
          python textbook_difficulty_system.py \
            --cognitive_load input_data.json \
            --scores input_data.json \
            --textbook textbook.json \
            --output results.json

          # è¾“å‡ºç»“æœ
          echo "ğŸ“Š Analysis results:"
          cat results.json

      # 6. è‡ªåŠ¨æäº¤ç»“æœ
      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          git add results.json
          git add input_data.json  # å¯é€‰ï¼šè®°å½•è¾“å…¥

          git commit -m "Auto-update: Analysis results for ${{ inputs.student_id }}" || echo "â¡ï¸ No changes to commit"
          git push

      # 7. ä¸Šä¼ åˆ° Google Apps Script (Google Drive)
      - name: Upload to Google Drive
        if: success()
        env:
          GAS_SCRIPT_URL: ${{ secrets.GAS_WEBAPP_URL }}
        run: |
          if [ -f "results.json" ]; then
            curl -X POST "$GAS_SCRIPT_URL" \
              -H "Content-Type: application/json" \
              --data-binary @results.json
            echo "ğŸ“¤ Results uploaded to Google Drive via GAS"
          else
            echo "âŒ results.json not found, upload skipped"
            exit 1
          fi

      # 8. é€šçŸ¥å®Œæˆï¼ˆå§‹ç»ˆè¿è¡Œï¼‰
      - name: Notify completion
        if: always()
        run: |
          echo "âœ… Analysis completed for student ${{ inputs.student_id }}"
          echo "ğŸ“Œ View results: https://github.com/zhaofz635/learning_system_automation/blob/main/results.json"
          echo "ğŸ•’ Workflow finished at $(date)"
