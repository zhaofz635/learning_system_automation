name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: 'å­¦ç”ŸID (å¦‚ test001)'
        required: true
        type: string
      score:
        description: 'æµ‹è¯•æˆç»© (0-5åˆ†)'
        required: true
        type: string
      cognitive_load:
        description: 'è®¤çŸ¥è´Ÿè·è¯„åˆ† (1-5åˆ†ï¼Œé€—å·åˆ†éš”)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      # 1. æ£€å‡ºä»£ç 
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. è®¾ç½® Python ç¯å¢ƒ
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. é…ç½® NLTK ç¯å¢ƒå˜é‡ï¼ˆå…³é”®ï¼šæ—©äºæ‰€æœ‰ Python æ­¥éª¤ï¼‰
      - name: Configure NLTK_DATA environment
        run: |
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV
          mkdir -p /tmp/nltk_data

      # 4. å®‰è£…ä¾èµ–å¹¶ä¸‹è½½ NLTK æ•°æ®
      - name: Install dependencies and download NLTK data
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install nltk

          python -c "
          import nltk
          print('ğŸ“¥ Downloading NLTK book collection...')
          nltk.download('book', download_dir='/tmp/nltk_data', quiet=False)
          print('âœ… NLTK data downloaded to /tmp/nltk_data')
          "

      # 5. éªŒè¯ tokenization æ˜¯å¦å¯ç”¨
      - name: Validate NLTK setup
        run: |
          python -c "
          import nltk
          tokens = nltk.word_tokenize('Hello, world!')
          print(f'âœ… Success: {tokens}')
          "

      # 6. å‡†å¤‡è¾“å…¥æ•°æ®
      - name: Prepare input files
        run: |
          echo '{
            "student_id": "${{ inputs.student_id }}",
            "score": ${{ inputs.score }},
            "cognitive_load": [${{ inputs.cognitive_load }}]
          }' > input_data.json
          cat input_data.json

      # 7. è¿è¡Œåˆ†æè„šæœ¬ï¼ˆç¡®ä¿ç¯å¢ƒå˜é‡ä¼ é€’ï¼‰
      - name: Run analysis script
        env:
          Access_Key_Secret: ${{ secrets.Access_Key_Secret }}
          NLTK_DATA: ${{ env.NLTK_DATA }}  # âœ… æ˜¾å¼ä¼ é€’ç¯å¢ƒå˜é‡
        run: |
          set -e  # ğŸ”¥ å¤±è´¥ç«‹å³é€€å‡ºï¼Œä¾¿äºè°ƒè¯•
          echo "ğŸ” Current NLTK data paths:"
          python -c "import nltk; print(nltk.data.path)"

          # âœ… å…³é”®ï¼šåœ¨è¿è¡Œå‰å†æ¬¡éªŒè¯
          python -c "
          import nltk
          try:
              print(nltk.word_tokenize('Test sentence.'))
          except Exception as e:
              print('âŒ Tokenization failed in script context:')
              print(e)
              exit(1)
          "

          python textbook_difficulty_system.py \
            --cognitive_load input_data.json \
            --scores input_data.json \
            --textbook textbook.json \
            --output results.json

          cat results.json

      # 8. æäº¤ç»“æœ
      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add results.json input_data.json
          git commit -m "Auto: Results for ${{ inputs.student_id }}" || echo "No changes to commit"
          git push

      # 9. ä¸Šä¼ åˆ° Google Drive
      - name: Upload to Google Drive
        if: success()
        env:
          GAS_SCRIPT_URL: ${{ secrets.GAS_WEBAPP_URL }}
        run: |
          curl -X POST "$GAS_SCRIPT_URL" \
            -H "Content-Type: application/json" \
            --data-binary @results.json

      # 10. å®Œæˆé€šçŸ¥
      - name: Notify completion
        if: always()
        run: |
          echo "âœ… Analysis completed for ${{ inputs.student_id }}"
          echo "ğŸ“Œ Results: https://github.com/zhaofz635/learning_system_automation/blob/main/results.json"
