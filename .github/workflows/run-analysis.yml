name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: '学生ID (如 test001)'
        required: true
        type: string
      score:
        description: '测试成绩 (0-5分)'
        required: true
        type: string
      cognitive_load:
        description: '认知负荷评分 (1-5分，逗号分隔)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Verify python & pip path and versions
        run: |
          echo "Python path: $(which python)"
          echo "Pip path: $(which pip)"
          python --version
          pip --version
          python -m pip list

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install \
            numpy<2.0.0 \
            scipy<2.0.0 \
            pandas==1.5.3 \
            scikit-learn==1.2.2 \
            xgboost==1.7.6 \
            opencv-python-headless==4.8.0.76 \
            nltk==3.7 \
            requests==2.31.0

      - name: Verify requests installed
        run: |
          python -c "import requests; print(f'Requests version: {requests.__version__}')"

      - name: Prepare NLTK data directory and download resources
        run: |
          mkdir -p /tmp/nltk_data
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV
          python -c "
          import nltk
          import os
          nltk.data.path.append(os.environ['NLTK_DATA'])
          nltk.download('punkt', download_dir=os.environ['NLTK_DATA'])
          nltk.download('averaged_perceptron_tagger', download_dir=os.environ['NLTK_DATA'])
          nltk.download('stopwords', download_dir=os.environ['NLTK_DATA'])
          nltk.download('wordnet', download_dir=os.environ['NLTK_DATA'])
          nltk.download('book', download_dir=os.environ['NLTK_DATA'])
          print('✅ NLTK resources downloaded')
          "

      - name: Prepare input files
        run: |
          cognitive_load_array=$(echo "${{ inputs.cognitive_load }}" | tr ',' ' ')
          cat > input_data.json <<EOF
          {
            "student_id": "${{ inputs.student_id }}",
            "score": ${{ inputs.score }},
            "cognitive_load": [${cognitive_load_array// /,}]
          }
          EOF
          echo "Input data:"
          cat input_data.json

      - name: Run analysis script
        env:
          MINIMAX_API_KEY: ${{ secrets.MINIMAX_API_KEY }}
          NLTK_DATA: /tmp/nltk_data
        run: |
          python textbook_difficulty_system.py \
            --cognitive_load input_data.json \
            --scores input_data.json \
            --textbook textbook.json \
            --output results.json

          echo "Analysis results:"
          cat results.json

      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add results.json
          git commit -m "Auto: Results for ${{ inputs.student_id }} [skip ci]" || echo "No changes"
          git push

      - name: Upload to Google Sheets
        if: success()
        continue-on-error: true
        env:
          GAS_SCRIPT_URL: ${{ secrets.GAS_WEBAPP_URL }}
        run: |
          curl --fail --show-error --retry 3 \
            -X POST "$GAS_SCRIPT_URL" \
            -H "Content-Type: application/json" \
            --data-binary @results.json

      - name: Notify status
        if: always()
        run: |
          echo "✅ Workflow completed with status: ${{ job.status }}"
          echo "🔗 Results file: https://github.com/${{ github.repository }}/blob/main/results.json"
