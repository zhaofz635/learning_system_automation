name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: '学生ID (如 test001)'
        required: true
        type: string
      score:
        description: '测试成绩 (0-5分)'
        required: true
        type: string
      cognitive_load:
        description: '认知负荷评分 (1-5分，逗号分隔)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 20  # 增加超时时间
    env:
      NLTK_DATA: /tmp/nltk_data  # 全局环境变量

    steps:
      # 1. 检出代码
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. 设置Python环境
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      # 3. 缓存NLTK数据
      - name: Cache NLTK Data
        uses: actions/cache@v3
        with:
          path: /tmp/nltk_data
          key: ${{ runner.os }}-nltk-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-nltk-
# 新增：安装系统依赖（OpenCV所需）
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-opencv libopencv-dev

      # 4. 安装依赖（使用固定版本）
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install \
            nltk==3.7 \
            pandas==1.5.3 \
            scikit-learn==1.2.2 \
            xgboost==1.7.6
            opencv-python-headless==4.8.0  # 新增

      # 5. 设置NLTK环境
      - name: Setup NLTK
        run: |
          mkdir -p /tmp/nltk_data
          chmod -R 777 /tmp/nltk_data
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV

          # 强制下载所有必需资源
          python -c "
          import nltk, os
          nltk.download('punkt', download_dir=os.environ['NLTK_DATA'], quiet=False)
          nltk.download('punkt_tab', download_dir=os.environ['NLTK_DATA'], quiet=False)
          nltk.download('book', download_dir=os.environ['NLTK_DATA'], quiet=False)
          print('✅ 关键NLTK资源已下载')
          "

      # 6. 验证NLTK
      - name: Validate NLTK
        run: |
          python -c "
          import nltk, os
          nltk.data.path.insert(0, os.environ['NLTK_DATA'])
          try:
              print('找到punkt:', nltk.data.find('tokenizers/punkt'))
              print('找到punkt_tab:', nltk.data.find('tokenizers/punkt_tab/english'))
              print('分词测试:', nltk.word_tokenize('This is a test.'))
              print('✅ NLTK验证通过')
          except Exception as e:
              print('❌ NLTK验证失败:', str(e))
              exit(1)
          "

      # 7. 准备输入数据
      - name: Prepare input files
        run: |
          cognitive_load_array=$(echo "${{ inputs.cognitive_load }}" | tr ',' ' ')
          cat > input_data.json <<EOF
          {
            "student_id": "${{ inputs.student_id }}",
            "score": ${{ inputs.score }},
            "cognitive_load": [${cognitive_load_array// /,}]
          }
          EOF
          echo "输入文件内容:"
          jq . input_data.json || cat input_data.json

      # 8. 运行分析脚本
      - name: Run analysis
        env:
          MINIMAX_API_KEY: ${{ secrets.MINIMAX_API_KEY }}
          NLTK_DATA: /tmp/nltk_data
        run: |
          python -c "
          import nltk, os
          nltk.data.path.insert(0, os.environ['NLTK_DATA'])
          print('当前NLTK路径:', nltk.data.path)
          "
          
          # 带重试的运行机制
          max_attempts=3
          attempt=1
          while [ $attempt -le $max_attempts ]; do
            echo "尝试第 $attempt 次运行..."
            python textbook_difficulty_system.py \
              --cognitive_load input_data.json \
              --scores input_data.json \
              --textbook textbook.json \
              --output results.json && break
            attempt=$((attempt + 1))
            sleep 5
          done
          
          if [ $attempt -gt $max_attempts ]; then
            echo "❌ 运行失败，已达最大尝试次数"
            exit 1
          fi
          
          echo "分析结果:"
          jq . results.json || cat results.json

      # 9. 提交结果
      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add results.json
          git commit -m "Auto: Results for ${{ inputs.student_id }} [skip ci]" || echo "无变更可提交"
          
          # 使用token推送
          remote_repo="https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/${GITHUB_REPOSITORY}.git"
          git push "${remote_repo}" HEAD:${GITHUB_REF} || exit 0

      # 10. 上传到Google Sheets
      - name: Upload to Google Sheets
        continue-on-error: true
        env:
          GAS_SCRIPT_URL: ${{ secrets.GAS_WEBAPP_URL }}
        run: |
          curl --fail --show-error --retry 3 \
            -X POST "$GAS_SCRIPT_URL" \
            -H "Content-Type: application/json" \
            --data-binary @results.json

      # 11. 最终状态通知
      - name: Notify status
        if: always()
        run: |
          echo "工作流状态: ${{ job.status }}"
          echo "结果文件: https://github.com/$GITHUB_REPOSITORY/blob/$GITHUB_REF/results.json"
          echo "详细日志: https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID"
