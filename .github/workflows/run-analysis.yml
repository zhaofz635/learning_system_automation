name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: '学生ID (如 test001)'
        required: true
        type: string
      score:
        description: '测试成绩 (0-5分)'
        required: true
        type: string
      cognitive_load:
        description: '认知负荷评分 (1-5分，逗号分隔)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      NLTK_DATA: /tmp/nltk_data  # NLTK 数据根目录

    steps:
      # 1. 检出代码
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. 设置 Python 环境
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. 安装依赖并下载 NLTK 数据（推荐方式）
      - name: Install dependencies and NLTK data
        run: |
          # 升级 pip 并安装依赖
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install nltk

          # 创建 NLTK 数据目录
          mkdir -p /tmp/nltk_data

          # 🔑 核心：使用 NLTK 官方推荐的 'book' 集合
          # 包含：punkt, punkt_tab, stopwords, wordnet, averaged_perceptron_tagger 等
          python -c "
          import nltk
          print('📥 Downloading NLTK book collection (official recommended)...')
          nltk.download('book', download_dir='/tmp/nltk_data', quiet=False)
          print('✅ NLTK data installed.')
          "

          # ✅ 将自定义路径添加到 nltk 搜索路径（关键！）
          python -c "
          import nltk
          nltk.data.path.append('/tmp/nltk_data')  # 确保能加载 punkt_tab
          tokens = nltk.word_tokenize('Hello, world! This is a test.')
          print(f'✅ Tokenization works: {tokens}')
          "

          # 设置环境变量供后续步骤使用
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV

      # 4. 准备输入数据
      - name: Prepare input files
        run: |
          echo '{
            "student_id": "${{ inputs.student_id }}",
            "score": ${{ inputs.score }},
            "cognitive_load": [${{ inputs.cognitive_load }}]
          }' > input_data.json
          cat input_data.json

      # 5. 运行分析脚本
      - name: Run analysis script
        env:
          Access_Key_Secret: ${{ secrets.Access_Key_Secret }}
        run: |
          python textbook_difficulty_system.py \
            --cognitive_load input_data.json \
            --scores input_data.json \
            --textbook textbook.json \
            --output results.json
          cat results.json

      # 6. 提交结果
      - name: Commit results
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add results.json input_data.json
          git commit -m "Auto: Results for ${{ inputs.student_id }}" || echo "No changes to commit"
          git push

      # 7. 上传到 Google Drive
      - name: Upload to Google Drive
        if: success()
        env:
          GAS_SCRIPT_URL: ${{ secrets.GAS_WEBAPP_URL }}
        run: |
          curl -X POST "$GAS_SCRIPT_URL" \
            -H "Content-Type: application/json" \
            --data-binary @results.json

      # 8. 完成通知
      - name: Notify completion
        if: always()
        run: |
          echo "✅ Analysis completed for ${{ inputs.student_id }}"
          echo "📌 Results: https://github.com/zhaofz635/learning_system_automation/blob/main/results.json"
