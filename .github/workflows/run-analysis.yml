name: Textbook Analysis Pipeline

on:
  workflow_dispatch:
    inputs:
      student_id:
        description: '学生ID (如 test001)'
        required: true
        type: string
      score:
        description: '测试成绩 (0-5分)'
        required: true
        type: string
      cognitive_load:
        description: '认知负荷评分 (1-5分，逗号分隔)'
        required: true
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      NLTK_DATA: /tmp/nltk_data  # 全局环境变量

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Create NLTK data directory
        run: |
          sudo mkdir -p /tmp/nltk_data
          sudo chmod -R 777 /tmp/nltk_data
          echo "NLTK_DATA=/tmp/nltk_data" >> $GITHUB_ENV

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install nltk==3.8.1  # 使用稳定版本

      - name: Download NLTK resources (full set)
        run: |
          python -c "
import nltk
nltk.download('punkt', download_dir='$NLTK_DATA')
nltk.download('punkt_tab', download_dir='$NLTK_DATA')  # 新增
nltk.download('averaged_perceptron_tagger', download_dir='$NLTK_DATA')
nltk.download('stopwords', download_dir='$NLTK_DATA')
nltk.download('wordnet', download_dir='$NLTK_DATA')
nltk.download('book', download_dir='$NLTK_DATA')
print('✅ NLTK资源下载完成')
          "

      - name: Validate NLTK setup
        run: |
          python -c "
import nltk
nltk.data.path.append('$NLTK_DATA')
print(nltk.data.find('tokenizers/punkt'))
print(nltk.data.find('tokenizers/punkt_tab'))
print(nltk.word_tokenize('Hello world. This is a test.'))
print('✅ NLTK验证通过')
          "

      - name: Prepare input files
        run: |
          cognitive_load_array=$(echo "${{ inputs.cognitive_load }}" | tr ',' ' ')
          cat > input_data.json <<EOF
          {
            "student_id": "${{ inputs.student_id }}",
            "score": ${{ inputs.score }},
            "cognitive_load": [${cognitive_load_array// /,}]
          }
          EOF
          echo "输入文件内容:"
          jq . input_data.json || cat input_data.json

      - name: Run analysis script
        env:
          MINIMAX_API_KEY: ${{ secrets.MINIMAX_API_KEY }}
          NLTK_DATA: /tmp/nltk_data
        run: |
          python -c "import nltk; print(f'NLTK数据路径: {nltk.data.path}')"
          python textbook_difficulty_system.py \
            --cognitive_load input_data.json \
            --scores input_data.json \
            --textbook textbook.json \
            --output results.json
          echo "分析结果:"
          jq . results.json || cat results.json

      - name: Commit results
       
